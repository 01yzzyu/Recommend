{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ef814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import List, Tuple\n",
    "import tensorflow as tf\n",
    "from Recommender_System.utility.decorator import logger\n",
    "from Recommender_System.utility.evaluation import TopkData\n",
    "from Recommender_System.algorithm.train import prepare_ds, get_score_fn\n",
    "from Recommender_System.algorithm.common import log, topk\n",
    "\n",
    "\n",
    "@logger('开始训练，', ('epochs', 'batch'))\n",
    "def train(model: tf.keras.Model, train_data: List[Tuple[int, int, int]], test_data: List[Tuple[int, int, int]],\n",
    "          topk_data: TopkData = None, optimizer=None, epochs=100, batch=512):\n",
    "    if optimizer is None:\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    train_ds, test_ds = prepare_ds(train_data, test_data, batch)\n",
    "\n",
    "    loss_mean_metric = tf.keras.metrics.Mean()\n",
    "    auc_metric = tf.keras.metrics.AUC()\n",
    "    precision_metric = tf.keras.metrics.Precision()\n",
    "    recall_metric = tf.keras.metrics.Recall()\n",
    "    loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "    if topk_data:\n",
    "        score_fn = get_score_fn(model)\n",
    "\n",
    "    def reset_metrics():\n",
    "        for metric in [loss_mean_metric, auc_metric, precision_metric, recall_metric]:\n",
    "            tf.py_function(metric.reset_states, [], [])\n",
    "\n",
    "    def update_metrics(loss, label, score):\n",
    "        loss_mean_metric.update_state(loss)\n",
    "        auc_metric.update_state(label, score)\n",
    "        precision_metric.update_state(label, score)\n",
    "        recall_metric.update_state(label, score)\n",
    "\n",
    "    def get_metric_results():\n",
    "        return loss_mean_metric.result(), auc_metric.result(), precision_metric.result(), recall_metric.result()\n",
    "\n",
    "    @tf.function\n",
    "    def train_batch(ui, label):\n",
    "        with tf.GradientTape() as tape:\n",
    "            score = model(ui, training=True)\n",
    "            loss = loss_object(label, score) + sum(model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        update_metrics(loss, label, score)\n",
    "\n",
    "    @tf.function\n",
    "    def test_batch(ui, label):\n",
    "        score = model(ui)\n",
    "        loss = loss_object(label, score) + sum(model.losses)\n",
    "        update_metrics(loss, label, score)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        reset_metrics()\n",
    "        for ui, label in train_ds:\n",
    "            train_batch(ui, label)\n",
    "        train_loss, train_auc, train_precision, train_recall = get_metric_results()\n",
    "\n",
    "        reset_metrics()\n",
    "        for ui, label in test_ds:\n",
    "            test_batch(ui, label)\n",
    "        test_loss, test_auc, test_precision, test_recall = get_metric_results()\n",
    "\n",
    "        log(epoch, train_loss, train_auc, train_precision, train_recall, test_loss, test_auc, test_precision, test_recall)\n",
    "        if topk_data:\n",
    "            topk(topk_data, score_fn)\n",
    "        print('epoch_time=', time.time() - epoch_start_time, 's', sep='')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
