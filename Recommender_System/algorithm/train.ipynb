{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23840ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Callable, Dict  # 导入类型注解，用于代码类型检查和文档目的。\n",
    "import tensorflow as tf  # 导入TensorFlow库，用于机器学习和神经网络。\n",
    "\n",
    "# 导入自定义模块，可能包含日志、工具函数和评估方法。\n",
    "from Recommender_System.algorithm.common import log, topk\n",
    "from Recommender_System.utility.evaluation import TopkData\n",
    "from Recommender_System.utility.decorator import logger\n",
    "\n",
    "# 函数prepare_ds：准备训练和测试数据集\n",
    "def prepare_ds(train_data: List[Tuple[int, int, int]], test_data: List[Tuple[int, int, int]],\n",
    "               batch: int) -> Tuple[tf.data.Dataset, tf.data.Dataset]:\n",
    "    # 定义函数xy：从原始数据创建用户ID、物品ID和标签的张量\n",
    "    def xy(data):\n",
    "        user_ids = tf.constant([d[0] for d in data], dtype=tf.int32)\n",
    "        item_ids = tf.constant([d[1] for d in data], dtype=tf.int32)\n",
    "        labels = tf.constant([d[2] for d in data], dtype=tf.keras.backend.floatx())\n",
    "        return {'user_id': user_ids, 'item_id': item_ids}, labels\n",
    "\n",
    "    # 创建训练和测试数据集\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(xy(train_data)).shuffle(len(train_data)).batch(batch)\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices(xy(test_data)).batch(batch)\n",
    "\n",
    "    return train_ds, test_ds\n",
    "\n",
    "# 函数_evaluate：评估模型的性能\n",
    "def _evaluate(model, dataset, loss_object, mean_metric=tf.keras.metrics.Mean(), auc_metric=tf.keras.metrics.AUC(),\n",
    "              precision_metric=tf.keras.metrics.Precision(), recall_metric=tf.keras.metrics.Recall()):\n",
    "    for metric in [mean_metric, auc_metric, precision_metric, recall_metric]:\n",
    "        tf.py_function(metric.reset_states, [], [])  # 重置评估指标\n",
    "\n",
    "    # 定义函数evaluate_batch：评估单个批次\n",
    "    @tf.function\n",
    "    def evaluate_batch(ui, label):\n",
    "        score = tf.squeeze(model(ui))\n",
    "        loss = loss_object(label, score) + sum(model.losses)\n",
    "        return score, loss\n",
    "\n",
    "    # 对数据集中的每个批次进行评估\n",
    "    for ui, label in dataset:\n",
    "        score, loss = evaluate_batch(ui, label)\n",
    "\n",
    "        # 更新评估指标\n",
    "        mean_metric.update_state(loss)\n",
    "        auc_metric.update_state(label, score)\n",
    "        precision_metric.update_state(label, score)\n",
    "        recall_metric.update_state(label, score)\n",
    "\n",
    "    # 返回计算的评估指标结果\n",
    "    return mean_metric.result(), auc_metric.result(), precision_metric.result(), recall_metric.result()\n",
    "\n",
    "# 函数_train_graph：使用TensorFlow图模式进行模型训练\n",
    "def _train_graph(model, train_ds, test_ds, topk_data, optimizer, loss_object, epochs):\n",
    "    score_fn = get_score_fn(model)  # 获取模型分数函数\n",
    "\n",
    "    # 定义函数train_batch：训练单个批次\n",
    "    @tf.function\n",
    "    def train_batch(ui, label):\n",
    "        with tf.GradientTape() as tape:\n",
    "            score = tf.squeeze(model(ui, training=True))\n",
    "            loss = loss_object(label, score) + sum(model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # 进行多个训练周期\n",
    "    for epoch in range(epochs):\n",
    "        for ui, label in train_ds:\n",
    "            train_batch(ui, label)\n",
    "\n",
    "        # 在训练和测试集上评估模型\n",
    "        train_loss, train_auc, train_precision, train_recall = _evaluate(model, train_ds, loss_object)\n",
    "        test_loss, test_auc, test_precision, test_recall = _evaluate(model, test_ds, loss_object)\n",
    "\n",
    "        # 记录日志并执行topk评估\n",
    "        log(epoch, train_loss, train_auc, train_precision, train_recall, test_loss, test_auc, test_precision, test_recall)\n",
    "        topk(topk_data, score_fn)\n",
    "\n",
    "# 函数_train_eager：使用Eager Execution模式进行模型训练\n",
    "def _train_eager(model, train_ds, test_ds, topk_data, optimizer, loss_object, epochs):\n",
    "    model.compile(optimizer=optimizer, loss=loss_object, metrics=['AUC', 'Precision', 'Recall'])\n",
    "    model.fit(train_ds, epochs=epochs, verbose=0, validation_data=test_ds,\n",
    "              callbacks=[RsCallback(topk_data, get_score_fn(model))])\n",
    "\n",
    "# RsCallback类：自定义回调，用于在每个训练时期结束时执行特定操作\n",
    "class RsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, topk_data: TopkData, score_fn: Callable[[Dict[str, List[int]]], List[float]]):\n",
    "        super(RsCallback, self).__init__()\n",
    "        self.topk_data = topk_data  # 用于topk评估的数据\n",
    "        self.score_fn = score_fn  # 评分函数\n",
    "\n",
    "    # 定义on_epoch_end方法，每个训练时期结束时被调用\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # 获取日志数据，处理可能缺失的键\n",
    "        loss = logs.get('loss', 0)\n",
    "        auc = logs.get('auc', 0)\n",
    "        precision = logs.get('precision', 0)\n",
    "        recall = logs.get('recall', 0)\n",
    "        val_loss = logs.get('val_loss', 0)\n",
    "        val_auc = logs.get('val_auc', 0)\n",
    "        val_precision = logs.get('val_precision', 0)\n",
    "        val_recall = logs.get('val_recall', 0)\n",
    "\n",
    "        # 记录日志并进行topk评估\n",
    "        log(epoch, loss, auc, precision, recall, val_loss, val_auc, val_precision, val_recall)\n",
    "        topk(self.topk_data, self.score_fn)\n",
    "\n",
    "\n",
    "@logger('开始训练，', ('epochs', 'batch', 'execution'))\n",
    "def train(model: tf.keras.Model, train_data: List[Tuple[int, int, int]], test_data: List[Tuple[int, int, int]],\n",
    "          topk_data: TopkData, optimizer=None, loss_object=None, epochs=100, batch=512, execution='eager') -> None:\n",
    "    \"\"\"\n",
    "    通用训练流程。\n",
    "\n",
    "    :param model: 模型\n",
    "    :param train_data: 训练集\n",
    "    :param test_data: 测试集\n",
    "    :param topk_data: 用于topk评估数据\n",
    "    :param optimizer: 优化器，默认为Adam\n",
    "    :param loss_object: 损失函数，默认为BinaryCrossentropy\n",
    "    :param epochs: 迭代次数\n",
    "    :param batch: 批数量\n",
    "    :param execution: 执行模式，为eager或graph。在eager模式下，用model.fit；在graph模式下，用tf.function和GradientTape\n",
    "    \"\"\"\n",
    "    if optimizer is None:\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "    if loss_object is None:\n",
    "        loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    train_ds, test_ds = prepare_ds(train_data, test_data, batch)\n",
    "    train_fn = _train_eager if execution == 'eager' else _train_graph\n",
    "    train_fn(model, train_ds, test_ds, topk_data, optimizer, loss_object, epochs)\n",
    "\n",
    "\n",
    "@logger('开始测试，', ('batch',))\n",
    "def test(model: tf.keras.Model, train_data: List[Tuple[int, int, int]], test_data: List[Tuple[int, int, int]],\n",
    "         topk_data: TopkData, loss_object=None, batch=512) -> None:\n",
    "    \"\"\"\n",
    "    通用测试流程。\n",
    "\n",
    "    :param model: 模型\n",
    "    :param train_data: 训练集\n",
    "    :param test_data: 测试集\n",
    "    :param topk_data: 用于topk评估数据\n",
    "    :param loss_object: 损失函数，默认为BinaryCrossentropy\n",
    "    :param batch: 批数量\n",
    "    \"\"\"\n",
    "    if loss_object is None:\n",
    "        loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    train_ds, test_ds = prepare_ds(train_data, test_data, batch)\n",
    "    train_loss, train_auc, train_precision, train_recall = _evaluate(model, train_ds, loss_object)\n",
    "    test_loss, test_auc, test_precision, test_recall = _evaluate(model, test_ds, loss_object)\n",
    "    log(-1, train_loss, train_auc, train_precision, train_recall, test_loss, test_auc, test_precision, test_recall)\n",
    "    topk(topk_data, get_score_fn(model))\n",
    "\n",
    "\n",
    "# get_score_fn函数：获取用于评分的函数\n",
    "def get_score_fn(model):\n",
    "    # 定义_fast_model：一个经过优化，能快速评估的模型版本\n",
    "    @tf.function(experimental_relax_shapes=True)\n",
    "    def _fast_model(ui):\n",
    "        return tf.squeeze(model(ui))\n",
    "\n",
    "    # get_score_fn函数：返回一个用于计算分数的函数\n",
    "    def score_fn(ui):\n",
    "        ui = {k: tf.constant(v, dtype=tf.int32) for k, v in ui.items()}\n",
    "        return _fast_model(ui).numpy()\n",
    "\n",
    "    return score_fn\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
